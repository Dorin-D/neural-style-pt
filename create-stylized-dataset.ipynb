{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"de91546e-6bf0-4102-8330-cd9c473fa423","_uuid":"4beba73e-ae1f-414b-ba30-586c58e4f37b","collapsed":false,"execution":{"iopub.execute_input":"2022-12-12T20:24:19.329475Z","iopub.status.busy":"2022-12-12T20:24:19.328683Z","iopub.status.idle":"2022-12-12T20:24:21.756329Z","shell.execute_reply":"2022-12-12T20:24:21.754238Z","shell.execute_reply.started":"2022-12-12T20:24:19.329374Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["import os\n","import pandas as pd\n","import numpy as np\n","import neural_style\n","import download_models\n","from PIL import Image\n","import shutil\n","import random"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T20:33:03.476542Z","iopub.status.busy":"2022-12-12T20:33:03.475927Z","iopub.status.idle":"2022-12-12T20:33:03.524491Z","shell.execute_reply":"2022-12-12T20:33:03.522564Z","shell.execute_reply.started":"2022-12-12T20:33:03.476491Z"},"trusted":true},"outputs":[],"source":["def choose_classes(labels, n_classes, n_samples):\n","    \"\"\"\n","    Chooses n_classes that contain at least n_train, n_test : train,test samples from the given labels dataframe.\n","    parameters:\n","        labels: pandas dataframe containing filenames, labels and train/test split\n","        n_classes: required number of classes\n","        n_samples: required number of samples in a class\n","    returns:\n","        chosen_classes: an array of the names of the classes chosen    \n","    \"\"\"\n","    #number of classes\n","    total_classes = labels['CATEGORY'].nunique()\n","    #array of classes\n","    classes = labels.CATEGORY.unique()\n","\n","    assert total_classes >= n_classes, \"n_classes must be smaller than the number of available classes. (choose_classes function)\"\n","\n","    #create random permutation of n_classes from all classes\n","    class_random_sampling = np.arange(total_classes)\n","    class_random_sampling = np.random.permutation(class_random_sampling)\n","    \n","    samples_per_class = labels.groupby(['CATEGORY'])['ORIG_CATEGORY_FILENAME'].count().reset_index(name='count')\n","    chosen_classes = []\n","    for c in class_random_sampling:\n","        samples_per_current_class = samples_per_class.loc[samples_per_class['CATEGORY']==classes[c]]\n","        #get amount of rows in this class, as INTEGER instead of SERIES >.<\n","        samples_count_current_class = samples_per_current_class['count'].iloc[0]\n","        if (samples_count_current_class < n_samples):\n","            #if not enough samples, we ignore this class and take the next one\n","            continue\n","        chosen_classes.append(classes[c])\n","        \n","        if len(chosen_classes) == n_classes:\n","            break\n","\n","    return chosen_classes\n","\n","def choose_styles(labels, n_styles):\n","    \"\"\"\n","    Chooses n_styles randomly from the labels dataframe. \n","    parameters:\n","        labels: pandas dataframe containing filenames, style labels and train/test split of each file\n","        n_styles: number of styles to choose\n","    returns:\n","        chosen_styles: an array of the names of the styles chosen\n","    \"\"\"\n","    #number of style classes\n","    total_classes = labels['STYLE'].nunique()\n","    #array of classes\n","    classes = labels.STYLE.unique()\n","    \n","    assert total_classes >= n_styles, \"n_classes must be smaller than the number of available classes. (choose_styles function)\"\n","    \n","    #create random permutation of n_classes from all classes\n","    class_random_sampling = np.arange(total_classes)\n","    class_random_sampling = np.random.permutation(class_random_sampling)\n","\n","    chosen_styles = []\n","    for s in class_random_sampling:\n","        chosen_styles.append(classes[s])\n","        if chosen_styles == n_styles:\n","            break\n","    return chosen_styles\n"," \n","def choose_style_image(style_location, style):\n","    \"\"\"\n","    Given a style, finds its associated images using the label file in style_location and returns a random filename of the style.\n","    parameters:\n","        style_location: location containing the folder with style images and the label.csv\n","        style: name of the style\n","    returns:\n","        chosen_image: location of the chosen style image\n","    \"\"\"\n","    \n","    label = os.path.join(style_location, \"labels.csv\")\n","    images_location = os.path.join(style_location, \"data\")\n","\n","    label_csv = pd.read_csv(label)\n","    label_csv.rename(columns = {\"FILENAME\" : \"ORIG_STYLE_FILENAME\"}, inplace=True)\n","    \n","    #get all filenames of images of said style\n","    style_images = label_csv.loc[label_csv['STYLE']==style]['ORIG_STYLE_FILENAME']\n","    #choose a random image from this list\n","    random_index = int(len(style_images) * np.random.rand(1))\n","    chosen_image = style_images.iloc[random_index]\n","    return chosen_image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T20:33:03.740465Z","iopub.status.busy":"2022-12-12T20:33:03.739848Z","iopub.status.idle":"2022-12-12T20:33:05.021900Z","shell.execute_reply":"2022-12-12T20:33:05.020760Z","shell.execute_reply.started":"2022-12-12T20:33:03.740396Z"},"trusted":true},"outputs":[],"source":["def create_stylized_dataset(location, location_styles, n_classes, n_styles, \n","                            n_samples,\n","                            output_location,\n","        #the rest are remaining neural style transfer arguments\n","        p_style_weight=\"1e2\", p_content_weight=\"5e0\", p_num_iterations=\"1000\", p_learning_rate = \"1e0\", \n","        p_gpu=\"0\", p_image_size=\"512\", p_style_blend_weights=\"None\", p_normalize_weights=\"False\", p_normalize_gradients=\"False\", p_tv_weight=\"1e-3\", p_init='random', p_init_image=\"None\", p_optimizer='lbfgs', \n","        p_lbfgs_num_correction=\"100\",\n","        p_print_iter=\"0\", p_save_iter=\"0\", p_style_scale=\"1.0\", p_original_colors = \"0\", p_model_file='models/vgg19-d01eb7cb.pth', p_disable_check=\"False\",\n","        p_backend='nn', p_cudnn_autotune=\"False\", p_pooling='max',\n","        p_seed=\"-1\", p_content_layers='relu4_2', p_style_layers='relu1_1,relu2_1,relu3_1,relu4_1,relu5_1', p_multidevice_strategy='4,7,29'):\n","    \"\"\"\n","    Given a domain, applies style transfer to n_samples per each class,style group.\n","    Generates a .csv file which contains the filenames, the classes, and the assigned style to them.\n","    \n","    parameters:\n","        location: the location(s) of the domain(s) to be used; if multiple domains given, choose randomly;\n","                format of domain folders:\n","                    location_folder\n","                        >data\n","                            >>all images will be in this folder\n","                        >labels.csv\n","                            >>this file will contain the columns: filename, label, split\n","                                >>filename: name of the file\n","                                >>label: name of the class\n","                                N/A>>split: test or train; specifying the split of the sample\n","        location_styles: the location with the styles to be used; format:\n","            location_styles\n","                >data\n","                    >>all style images will be in this folder\n","                >labels.csv\n","                    >>this file will contain the columns: filename, label\n","                        >>filename: name of the style file\n","                        >>label: name of the style\n","                        N/A>>split: which split the style is in\n","\n","        n_classes: amount of classes from the dataset to apply styles to\n","        n_styles: amount of styles to apply\n","            (n_classes, n_styles) should be equal?\n","        n_samples: number of samples per class\n","        output_location: location where to output the label, data\n","    output:\n","        tbd\n","    \"\"\"\n","    if type(location)==str:\n","        pass\n","    elif type(location) in (list,tuple):\n","        location = random.choice(location)\n","    else:\n","        #you can't have neither a list, tuple nor a str!!!!\n","        raise Exception(\"Please don't do this to me (╥﹏╥)\")\n","    \n","    data = os.path.join(location, \"data\")\n","    label_loc = os.path.join(location, \"labels.csv\")\n","    labels = pd.read_csv(label_loc)\n","    \n","    #rename filename to orig category name\n","    labels.rename(columns = {\"FILENAME\" : \"ORIG_CATEGORY_FILENAME\"}, inplace=True)\n","    \n","    \n","    n_samples_per_class = n_styles*n_samples #e.g. 40 samples per group, 3 styles means we need 120 samples for a class\n","    \n","    chosen_classes = choose_classes(labels, n_classes, n_samples_per_class)\n","    print(\"You have selected %f classes!\" %len(chosen_classes))\n","    assert len(chosen_classes) == n_classes, \"Likely there aren't enough classes to have at least n_samples samples (too many or too little classes were chosen)\"\n","\n","    style_label_loc = os.path.join(location_styles, \"labels.csv\")\n","    style_labels = pd.read_csv(style_label_loc)    \n","    \n","    style_labels.rename(columns = {\"FILENAME\" : \"ORIG_STYLE_FILENAME\"}, inplace=True)\n","    \n","    chosen_styles = choose_styles(style_labels, n_styles)    \n","    assert len(chosen_styles) == n_styles, \"Likely there aren't enough styles offered in the style label.csv file\"\n","\n","    #the assumption is that n_classes, n_styles are equal\n","    \n","    groups_style_class = []\n","\n","    labels_wstyles = pd.DataFrame()\n","\n","\n","    for c in chosen_classes:\n","        #select samples from current class c\n","        samples = labels[labels['CATEGORY']==c].reset_index(drop=True)\n","        #get random permutations samples\n","        random_samples_permutation = np.random.permutation(np.arange(len(samples)))\n","        #reset indices of chosen samples\n","        chosen_samples = samples.iloc[random_samples_permutation[:n_samples_per_class]].reset_index(drop=True)\n","        #get permutations for group samples\n","        chosen_samples_permutation = np.random.permutation(np.arange(len(chosen_samples)))\n","        for s in chosen_styles:\n","            chosen_images = chosen_samples_permutation[:n_samples]\n","            \n","            chosen_samples_permutation = chosen_samples_permutation[n_samples:]\n","            #select first n_samples samples from permutation\n","            chosen_samples = samples.iloc[chosen_images][['ORIG_CATEGORY_FILENAME', 'CATEGORY']]            \n","            chosen_samples.loc[chosen_images, 'STYLE'] = s\n","\n","            labels_wstyles = pd.concat((labels_wstyles, chosen_samples), ignore_index=True)\n","\n","    #for all entries, choose a style image of given style\n","    style_location_list = []\n","    for index,row in labels_wstyles.iterrows():\n","        style_location_list.append(choose_style_image(location_styles, row['STYLE']))\n","\n","    style_location_df = pd.DataFrame(style_location_list, columns=['ORIG_STYLE_FILENAME'])\n","    labels_wstyles['ORIG_STYLE_FILENAME'] = style_location_df\n","    \n","    output_label = os.path.join(output_location, 'label.csv')\n","    output_data = os.path.join(output_location, \"data\")\n","\n","    #create folders necessary for output_data (and output_label)\n","    os.makedirs(output_data, exist_ok=True)\n","    \n","    labels_wstyles['FILENAME'] = labels_wstyles['ORIG_CATEGORY_FILENAME'] + \"_\" + labels_wstyles['ORIG_STYLE_FILENAME']\n","    labels_wstyles.to_csv(output_label)\n","\n","    #create stylised dataset\n","    for index,row in labels_wstyles.iterrows():\n","        location_style_image = os.path.join(location_styles, \"data\", row['ORIG_STYLE_FILENAME'])\n","        location_content_image = os.path.join(location, \"data\", row['ORIG_CATEGORY_FILENAME'])\n","        location_output_image = os.path.join(output_location, \"data\", row['FILENAME'])\n","        \n","        with Image.open(location_content_image) as img:\n","            width, height = img.size\n","            #choosing the smaller value between image size, and the requested p_image_size\n","            #target_image_size = int(max(width, height))\n","            target_image_size = min(p_image_size, int(max(width, height)))\n","            \n","        \n","        command = \"/kaggle/usr/lib/neural_style/neural_style.py -style_image %s -style_blend_weights %s -content_image %s -image_size %s -gpu %s -content_weight %s -style_weight %s normalize_weights %s -normalize_gradients %s -tv_weight %s -num_iterations %s -init %s -init_image %s -optimizer %s -learning_rate %s -lbfgs_num_correction %s -print_iter %s -save_iter %s -output_image %s -style_scale %s -original_colors %s -pooling %s -model_file %s -disable_check %s -backend %s -cudnn_autotune %s -seed %s -content_layers %s -style_layers %s -multidevice_strategy %s\" %(\n","                location_style_image, p_style_blend_weights, location_content_image, target_image_size, p_gpu, p_content_weight, p_style_weight, p_normalize_weights, p_normalize_gradients, p_tv_weight, p_num_iterations, p_init, p_init_image, p_optimizer, p_learning_rate, p_lbfgs_num_correction, p_print_iter, p_save_iter, location_output_image, p_style_scale, p_original_colors, p_pooling, p_model_file, p_disable_check, p_backend, p_cudnn_autotune, p_seed, p_content_layers, p_style_layers, p_multidevice_strategy)\n","        !python3 $command\n","        print(\"Finished running: %s\" %command)\n","                    \n","    return 0"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T20:33:05.024641Z","iopub.status.busy":"2022-12-12T20:33:05.024272Z","iopub.status.idle":"2022-12-12T20:33:05.038950Z","shell.execute_reply":"2022-12-12T20:33:05.037918Z","shell.execute_reply.started":"2022-12-12T20:33:05.024606Z"},"trusted":true},"outputs":[],"source":["p_model_location = \"/kaggle/working/models\"\n","download_models.main(p_model_location)\n","p_model_file = os.path.join(p_model_location, \"vgg19-d01eb7cb.pth\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T20:33:05.041187Z","iopub.status.busy":"2022-12-12T20:33:05.040761Z","iopub.status.idle":"2022-12-12T20:44:37.595767Z","shell.execute_reply":"2022-12-12T20:44:37.594104Z","shell.execute_reply.started":"2022-12-12T20:33:05.041148Z"},"trusted":true},"outputs":[],"source":["location = \"/kaggle/input/ter-set-1/Human_Actions/Human_Actions\"\n","location_styles = \"/kaggle/input/ter-set-1/final_standardised/final_standardised\"\n","n_classes = 4\n","n_styles = 3\n","n_samples = 40\n","\n","output_location = \"/kaggle/working/output/Human_Actions_Stylized_Experiment_15122022\"\n","\n","create_stylized_dataset(location, location_styles, n_classes, n_styles, n_samples, output_location,\n","                        p_model_file = p_model_file, p_original_colors = \"1\", p_style_weight=25, p_image_size=512\n","        #the rest are remaining neural style transfer arguments\n","                       )\n","\"\"\"\n","        ,p_style_weight=1e2, p_content_weight=5e0, p_num_iterations=1000, p_learning_rate = 1e0, \n","        p_gpu=0, p_image_size=512, p_style_blend_weights=None, p_normalize_weights=False, p_normalize_gradients=False, p_tv_weight=1e-3, p_init='random', p_init_image=None, p_optimizer='lbfgs', \n","        p_lbfgs_num_correction=100,\n","        p_print_iter=0, p_save_iter=0, p_style_scale=1.0, p_original_colors = 0, p_model_file='models/vgg19-d01eb7cb.pth', p_disable_check=False, \n","        p_backend='nn', p_cudnn_autotune=False, p_pooling='max',\n","        p_seed=-1, p_content_layers='relu4_2', p_style_layers='relu1_1,relu2_1,relu3_1,relu4_1,relu5_1', p_multidevice_strategy='4,7,29')\n","\"\"\"\n","print()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T20:32:59.105834Z","iopub.status.busy":"2022-12-12T20:32:59.100767Z","iopub.status.idle":"2022-12-12T20:32:59.115444Z","shell.execute_reply":"2022-12-12T20:32:59.114454Z","shell.execute_reply.started":"2022-12-12T20:32:59.105762Z"},"trusted":true},"outputs":[],"source":["#shutil.rmtree(\"/kaggle/working/output/\")\n","#os.remove(\"/kaggle/working/output_archive.zip\")\n","#os.makedirs(\"/kaggle/working/\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-12T20:47:54.094905Z","iopub.status.busy":"2022-12-12T20:47:54.094505Z","iopub.status.idle":"2022-12-12T20:47:54.123795Z","shell.execute_reply":"2022-12-12T20:47:54.122489Z","shell.execute_reply.started":"2022-12-12T20:47:54.094869Z"},"trusted":true},"outputs":[],"source":["import shutil\n","shutil.make_archive(\"/kaggle/working/output_archive\", 'zip', \"/kaggle/working/output\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-07T11:06:43.592001Z","iopub.status.busy":"2022-12-07T11:06:43.591638Z","iopub.status.idle":"2022-12-07T11:06:43.600873Z","shell.execute_reply":"2022-12-07T11:06:43.599685Z","shell.execute_reply.started":"2022-12-07T11:06:43.591963Z"},"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
